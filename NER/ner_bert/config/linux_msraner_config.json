{
  "model_name": "ner",
  "epochs": 5,
  "checkpoint_every": 100,
  "eval_every": 100,
  "learning_rate": 2e-5,
  "sequence_length": 128,
  "ner_layers": [128],
  "ner_hidden_sizes": [128],
  "batch_size": 16,
  "num_classes": 7,
  "keep_prob": 0.9,
  "warmup_rate": 0.1,
  "output_path": "output",
  "bert_model_path": "../../data/chinese_roberta_wwm_ext_L-12_H-768_A-12/",
  "train_data": "data/msraner/test_sent.txt",
  "eval_data": "data/msraner/test_sent.txt",
  "ckpt_model_path": "ckpt_model/"
}